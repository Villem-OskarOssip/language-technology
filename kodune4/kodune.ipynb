{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import estnltk\n",
    "from estnltk import Text\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.tokenize.regexp import WhitespaceTokenizer\n",
    "import html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Korpuse töötlus\n",
    "def get_tagged_words(sisend, nr):\n",
    "    margendiga_laused = []\n",
    "    with open(sisend) as f:\n",
    "        read = f.readlines()\n",
    "        uuedRead = []\n",
    "        for rida in read:\n",
    "            if (rida.strip() not in [\"<p>\", \"</p>\", \"<s>\"] and len(rida.strip()) != 0):\n",
    "                uuedRead.append(rida.strip().lower())\n",
    "        li = []\n",
    "        for rida in uuedRead:\n",
    "            if rida.strip() == \"</s>\":\n",
    "                if len(li) != 0:\n",
    "                    margendiga_laused.append(li)\n",
    "                    li = []\n",
    "            else:\n",
    "                rida = html.unescape(rida)\n",
    "                sona = rida.split(None, 1)[0]\n",
    "                if nr == 1:\n",
    "                    margend = re.search(r\"//.*_(.*)_\", rida).group(1).upper()\n",
    "                    li.append((sona, margend))\n",
    "                if nr == 2:\n",
    "                    li.append(sona)\n",
    "    return margendiga_laused\n",
    "\n",
    "def loopFiles(path):\n",
    "    path = os.getcwd() + '/' + path\n",
    "    folder = os.listdir(path)\n",
    "    tagged = []\n",
    "    for file in folder:\n",
    "        tagged.extend(get_tagged_words(path + '/' + file, 1))\n",
    "    return tagged\n",
    "\n",
    "\n",
    "tagged_texts = loopFiles('train') # loen sisse treeninghulga\n",
    "test_texts = loopFiles('test') # loen sisse teshulga andmed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 2\n",
    "# kõigepealt teen erinevad märgendajad\n",
    "train_sents = tagged_texts\n",
    "default_tagger = nltk.DefaultTagger(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9373 BigramTagger\n",
      "0.9366 TrigramTagger\n",
      "0.8475 HiddenMarkovModelTagger\n"
     ]
    }
   ],
   "source": [
    "# prindin välja erinevate märgendajate evalutaionid\n",
    "test_sents = test_texts\n",
    "result = bigram_tagger_backoff.evaluate(test_sents)\n",
    "print ('{0:.4f} BigramTagger'.format(result))\n",
    "result = trigram_tagger_backoff.evaluate(test_sents)\n",
    "print (\"{0:.4f} TrigramTagger\".format(result))\n",
    "result = hmm_tagger.evaluate(test_sents)\n",
    "print (\"{0:.4f} HiddenMarkovModelTagger\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_tagged_words(os.getcwd() + '/' + 'ilu_0022.kym', 2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_tagged = bigram_tagger_backoff.tag_sents(result)\n",
    "tri_tagged = trigram_tagger_backoff.tag_sents(result)\n",
    "hmm_tagged = hmm_tagger.tag_sents(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['word'] = [w for s in result for w in s]\n",
    "df['bi_tag'] = [w[1] for s in bi_tagged for w in s]\n",
    "df['tri_tag'] = [w[1] for s in tri_tagged for w in s]\n",
    "df['hmm_tag'] = [w[1] for s in hmm_tagged for w in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Ossip_Villem-Oskar_4.csv\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models predictions contradicted on  304  occasions\n"
     ]
    }
   ],
   "source": [
    "# if any differences, filter these to get an overview\n",
    "unequal = df[(df['bi_tag'] != df['tri_tag']) | (df['bi_tag'] != df['hmm_tag'])]\n",
    "print(\"Models predictions contradicted on \", len(unequal), \" occasions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 EstNLTK1.4\n"
     ]
    }
   ],
   "source": [
    "def evaluate_estnltk(test_tagged):\n",
    "    correct = 0\n",
    "    all_cnt = sum(len(s) for s in test_tagged)\n",
    "    for s in test_tagged:\n",
    "        words = [w[0] for w in s]\n",
    "        tags = [w[1] for w in s]\n",
    "        lause = \" \".join(words)\n",
    "        lause = Text(lause)\n",
    "        estnltk_tags = lause.postags\n",
    "        for i in range(len(tags)):\n",
    "            if len(estnltk_tags) < i and tags[i] == estnltk_tags[i]:\n",
    "                correct += 1\n",
    "    return correct / all_cnt\n",
    "print(round(evaluate_estnltk(test_sents), 10), \"EstNLTK1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
